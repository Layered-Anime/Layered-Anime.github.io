
<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		        15px 15px 0 0px #fff, /* The fourth layer */
		        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		        20px 20px 0 0px #fff, /* The fifth layer */
		        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		        25px 25px 0 0px #fff, /* The fifth layer */
		        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
	    top: 50%;
	    transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
  <head>
		<title>Layered Temporal Dataset 
for Anime Drawings</title>
		<meta property="og:image" content="images/teaser3.jpg"/>
		<meta property="og:title" content="Layered Temporal Dataset 
for Anime Drawings" />
  </head>

  <body>
    <br>
          <center>
          	<span style="font-size:42px">Layered Temporal Dataset 
for Anime Drawings</span><br/>
	  		  <table align=center width=600px>
	  			  <tr>
	  	              <td align=center width=100px>
	  					<center>
	  						<span style="font-size:24px">Ningyuan ZHENG</span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=100px>
	  					<center>
	  						<span style="font-size:24px">Cheng-hsin Emily WUU</span>
		  		  		</center>
		  		  	  </td>
			  </table>
          		<!-- <span style="font-size:30px">ECCV 2016.</span> -->

	  		  <table align=center width=650px>
	  			  <tr>
	  	              <td align=center width=150px>
	  					<center>
	  						<span style="font-size:24px"><a href='https://drive.google.com/file/d/1a0XSSmCRzPIjNy6jBwZQM-1YwkNXPpX7/view?usp=sharing'> [Project Proporsal]</a></span>
		  		  		</center>
		  		  	  </td>
		  		  	  	  	              <td align=center width=150px>
	  					<center>
	  						<span style="font-size:24px"><a href='https://docs.google.com/presentation/d/1lEjxrpfoTagxFjvh-FG9gQsPDq2UwJV-AT8ueESirVA/edit?usp=sharing'> [Slides]</a></span>
		  		  		</center>
		  		  	  </td>
		  		  	 </tr>
	  			  <tr>
			  </table>
	  		  <table align=center width=800px>
	  	              <td align=center width=150px>
	  					<center>
	  						<span style="font-size:14px"><b><i>Update Date: May 15, 2021</i></b>
		  		  		</center>
		  		  	  </td>
		  		  	 </tr>
			  </table>
          </center>

<!--   		  <br><br>
		  <hr> -->

  		  <br>
  		  <table align=center width=850px>
  			  <tr>
  	              <td width=400px>
  					<center>
  	                	<a href="./images/teaser.png"><img class="rounded" src = "./images/teaser.png" height="500px"></img></href></a><br>
					</center>
  	              </td>
                </tr>
  	              <td width=400px>
  					<center>
  	                	<span style="font-size:14px"><i>Example  input: we collect the underlying stroke data in PSD format, containing composition and blending information for RGBA image layers. It captures the <b>temporality</b> of the creation of illustraion along with the <b>layered </b> information in each time stamp. </i>
					</center>
  	              </td>

  		  </table>



 	<table align=center width=850px>
	  		  <center><h1>Abstract</h1></center>
	  		  <tr>
	  		  	<td>

	  		    </td>
	  		  </tr>
			</table>

		In this project, we create a dataset of high-quality anime illustrations in PSD format (20,000 samples, ~1.6TB of raw size), which is useful for tackling self-supervised segmentation and generation refinement tasks.


		The dataset consisting of high-quality anime illustrations voted by online users. For each illustration sample, we collect the underlying stroke data that gives rise to the finishing work and replay the data through a drawing engine to render a series of PSD (PhotoShop Document) filesthat capture the art creation process. PSD format contains composition and blending information for RGBA image layers, which is useful for production, and the temporality nature of our data allows us to refine the sketches autoregressively. 

		We build a differentiable renderer for different channel blending modes
		that allows us to explore self-supervised segmentation tasks. 
		<br/>

To show the merit of our dataset, we established baseline for generation task with existing models such as MUNIT<a href='https://arxiv.org/abs/1611.07004
'>[4]</a> and Pix2Pix HD <a href='https://arxiv.org/pdf/1804.04732.pdf
'>[5]</a> Our next stage of works will be customizing model for generation/refinement task and establishing segmentation baseline with existing models.

  		  <br><br>

		  <hr>

  		  <table align=center width=1100px>
	  		 	<center><h1>Videos</h1></center>
  			  <tr>
		  		  <table align=center width=800px>
		  		    <tr>
		              <td align=center width=800px>
		              	<iframe width="800" height="450" src="https://www.youtube.com/embed/mfDHpirgTus" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
	
					  </td>
					</tr>
				  </table>
				<br>
                </tr>
  		  </table>
<br>
<hr>
		<br>

  		  <a name="related_work"></a>
  		  <table align=center width=1100px>
  			  <tr>
  	              <td width=400px>
  					<left>
	  		  <center><h1>Related Work</h1></center>
The success of modern computer vision approaches mostly attributes to the
growing data. Richly annotated and cross-modal datasets nowadays open avenues to various research topics. These methods have also been applied to the
anime domain, such as sketch colorization <a href='https://doi.org/https://doi.org/10.1145/3272127.3275090'>[3]</a> and image generation <a href='https://www.gwern.net/
Faces'>[1]</a>. Existing
datasets such as Danbooru <a href='https://www.gwern.net/Danbooru2020'>[2] </a>contain images of anime illustrations and tags
(4.2m images, 130m tags, 3.4TB total), enabling conditioned generation on tags.
However, real-world applications usually require more fine-grained control, such
as layered editing and refinement. Due to lack of such data, current data-driven
approaches fail to tackle these problems.


	  		  <br><br>

	  		  <!-- <br><br> -->

	  		  		<span style="font-size:24px"><center><b> Danbooru2020</b> </center></span><br>

  		  <table align=center width=850px>
  			  <tr>
  	              <td width=100px>
  					<center>
  	                	<a href="./images/danbooru2020.png"><img class="rounded" src = "./images/danbooru2020.png" height="200px"></img></href></a><br>
					</center>
  	              </td>
                </tr>
  	              <td width=100px>
  					<center>
  						
  	                	<span style="font-size:16px"><a href="https://www.gwern.net/Danbooru2020#samples">[Website]</a> <br><br>Danbooru2020 is a large-scale anime image database with 4.2m+ images annotated with 130m+ tags; it can be useful for machine learning purposes such as image recognition and generation.<br></span>
				</br>

					</center>
  	              </td>

  		  </table>
			</br>

					<br><br>
<span style="font-size:24px"><center><b> Style2paints</b> </center></span><br>
	  		  		<table align=center width=850px>
  			  <tr>
  	              <td width=100px>
  					<center>
  	                	<a href="./images/style2paintspng"><img class="rounded" src = "./images/style2paints.png" height="200px"></img></href></a><br>
					</center>
  	              </td>
                </tr>
  	              <td width=100px>
  					<center>
  						
  	                	<span style="font-size:16px"><a href="https://github.com/lllyasviel/style2paints">[Website]</a> <br><br>DStyle2paints V4 is the current best AI driven lineart colorization tool. Different from previous end-to-end image-to-image translation methods, style2paints V4 is the first system to colorize a lineart in real-life human workflow, and the outputs are layered.<br></span>
				</br>

					</center>
  	              </td>

  		  </table>
		  <br>
		  	
<hr>

  		<a name="deep_dream"></a>

  	  	<center><h1>Samples of Layered Temporal Dataset<br></h1></center>
<span style="font-size:24px"><center><b> Preprocessing & Postprocessing</b> </center></span><br>

  		  <table align=center width=850px>

  	              <td width=100px>
  					<center>
  						
  	                	<span style="font-size:16px">Describe how's (1) clean up (locality, using homography) (2) blender engine reply the creation process).<br></span>
				</br>

					</center>
  	              </td>

  		  </table>

  		  <span style="font-size:24px"><center><b> Samples</b> </center></span><br>

	  		  <table align=center width=1000px>
	  			  <tr>
	  	              <td width=330px>
	  					<center>
	  						<a href="./images/1.PNG"><img class="rounded" onmouseover="this.src='./images/1.PNG';" onmouseout="this.src='./images/1.PNG;" src = "./images/1.PNG" height = "150px"></a><br>
	  					<span style="font-size:16px">Final Illustration</span><br>
						</center>
					  </td>
	  	              <td width=330px>
	  					<center>
	  						<a href="./images/2.PNG"><img class="rounded" onmouseover="this.src='./images/2.PNG';" onmouseout="this.src='./images/2.PNG;" src = "./images/2.PNG" height = "150px"></a><br>
	  					<span style="font-size:16px">Layer 1 </span><br>
						</center>
					  </td>
	  	              <td width=330px>

	  					<center>
	  						<a href="./images/3.PNG"><img class="rounded" onmouseover="this.src='./images/3.PNG';" onmouseout="this.src='./images/3.PNG;" src = "./images/3.PNG" height = "150px"></a><br>
	  					<span style="font-size:16px">Layer 2</span><br>
						</center>
					  </td>
	                </tr>

	  			  <tr>
	  	              	  	              <td width=330px>
	  					<center>
	  						<a href="./images/4.PNG"><img class="rounded" onmouseover="this.src='./images/4.PNG';" onmouseout="this.src='./images/4.PNG;" src = "./images/4.PNG" height = "150px"></a><br>
	  					<span style="font-size:16px">Final Illustration</span>
						</center>
					  </td>
	  	              <td width=330px>
	  					<center>
	  						<a href="./images/5.PNG"><img class="rounded" onmouseover="this.src='./images/5.PNG';" onmouseout="this.src='./images/5.PNG;" src = "./images/5.PNG" height = "150px"></a><br>
	  					<span style="font-size:16px">Layer 1</span>
						</center>
					  </td>

	  	              <td width=330px>
	  					<center>
	  						<a href="./images/6.PNG"><img class="rounded" onmouseover="this.src='./images/6.PNG';" onmouseout="this.src='./images/6.PNG;" src = "./images/6.PNG" height = "150px"></a><br>
	  					<span style="font-size:16px">Layer 2</span>
						</center>
					  </td>
	                </tr>

	  		  </table>
	  		 <table align=center width=1000px>
	  		  		  			  <tr>
	  	              	  	              <td width=200px>
	  					<center>
	  						<a href="./images/7.PNG"><img class="rounded" onmouseover="this.src='./images/7.PNG';" onmouseout="this.src='./images/7.PNG;" src = "./images/7.PNG" height = "150px"></a><br>
	  					<span style="font-size:16px">Final Illustration</span>
						</center>
					  </td>
	  	              <td width=200px>
	  					<center>
	  						<a href="./images/8.PNG"><img class="rounded" onmouseover="this.src='./images/8.PNG';" onmouseout="this.src='./images/8.PNG;" src = "./images/8.PNG" height = "150px"></a><br>
	  					<span style="font-size:16px">Layer 1</span>
						</center>
					  </td>

	  	              <td width=200px>
	  					<center>
	  						<a href="./images/9.PNG"><img class="rounded" onmouseover="this.src='./images/9.PNG';" onmouseout="this.src='./images/9.PNG;" src = "./images/9.PNG" height = "150px"></a><br>
	  					<span style="font-size:16px">Layer 2</span>
						</center>
					  </td>

					  	  	              <td width=200px>
	  					<center>
	  						<a href="./images/10.PNG"><img class="rounded" onmouseover="this.src='./images/10.PNG';" onmouseout="this.src='./images/10.PNG;" src = "./images/10.PNG" height = "150px"></a><br>
	  					<span style="font-size:16px">Layer 3</span>
						</center>
					  </td>
	                </tr>
	  		  </table>

 			</td>
			</tr>
		</table>

		<br>

		 

<hr>
		<br>

  		  <a name="related_work"></a>
  		  <table align=center width=1100px>
  			  <tr>
  	              <td width=400px>
  					<left>
	  		   <center><h1>Task Description & Approach</h1></center>
	  		   We present 2 specific tasks that can be conqured by our layered temporal dataset. One is self-supervised generation refinmenet and the other is self-supervised segmentation. Along with the task description, we also describe the implementation details of our model for tackling the generation refinement task.
	  		  <br><br>

	  		  <!-- <br><br> -->

	  		  		<span style="font-size:24px"><center><b> Self-supervised Generation Refinement </b> </center></span><br>

  		  <table align=center width=850px>
  			  <tr>
  	              <td width=100px>
  					<center>
  	                	<a href="./images/generation.png"><img class="rounded" src = "./images/generation.png" height="200px"></img></href></a><br>
					</center>
  	              </td>
                </tr>
  	              <td width=100px>
  					<center>
  						<br>
  						
  	                	<span style="font-size:16px">For this task, the input is a sketch, and the output is a refined illustration. 
<br>Our dataset enables generalized refining illustration using different layers and during the creation process.<br>APPROACH???!?!?!!?!</span>
				</br>

					</center>
  	              </td>

  		  </table>
			</br>

					<br>


  		  <span style="font-size:24px"><center><b> Self-supervised Segmentation</b> </center></span><br>

  		  <table align=center width=850px>
  			  <tr>
  	              <td width=100px>
  					<center>
  	                	<a href="./images/segmentation.png"><img class="rounded" src = "./images/segmentation.png" height="200px"></img></href></a><br>
					</center>
  	              </td>
                </tr>
  	              <td width=100px>
  					<center><br>
  	                	<span style="font-size:16px">For this task, the input is an illustration, and the output is a batch of segmented layers.
<br>Our dataset enables fine-grained segmentation of layers on any illustration (unknown layer information).
  						<br></span>
				</br>

					</center>
  	              </td>

  		  </table>
			</br>


		  <hr>

  		  <a name="bw_legacy"></a>
  		  <center><h1>Results on Generation Refinement Task</h1></center>
  		  <center>We show results on using conditional generation model MUNIT.<a href='https://arxiv.org/abs/1611.07004
'>[4]</a></center><br>

  		  <!-- along with miscellaneous photos. -->
  		  <br>
  		  <table align=center width=1000px>
  			  <tr>
  	              <td width=500px>
  					<center>
  						<a href="./images/g1.png"><img src = "./images/g1.png" height="400px"></img></href></a><br>
  
  				</center>
  	              </td>
 
                </tr>
  		  </table>
  		    		  <br>
  		  <table align=center width=800px>
  			  <tr>
  	              <td width=400px>
  					<center>
  						<a href="./images/g2.png"><img src = "./images/g2.png" height="300px"></img></href></a><br>
 
  				</center>
  	              </td>
                </tr>
  		  </table>

  		<br><br>  
  	  	
		  
		<br><br>

		<hr>
		


    <center><h1>References</h1></center>
    <p style="width: 80%;">
    [1]Gwern: Making anime faces with stylegan (Feb 2019), https://www.gwern.net/
Faces
    </p>
    <p style="width: 80%;">
    [2]Gwern: Danbooru2020: A large-scale crowdsourced and tagged anime illustration
dataset (Jan 2021), https://www.gwern.net/Danbooru2020
    </p>
    <p style="width: 80%;">
    [3]LvMin Zhang, Chengze Li, T.T.W.Y.J., Liu, C.: Two-stage sketch
colorization. ACM Transactions on Graphics 37(6) (Nov 2018).
https://doi.org/https://doi.org/10.1145/3272127.3275090
    </p>
    <p style="width: 80%;">
    [4]Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser,
L., Polosukhin, I.: Attention is all you need. CoRR abs/1706.03762 (2017), http:
//arxiv.org/abs/1706.03762
    </p>
        <p style="width: 80%;">
    [5]Wang, T.C., Liu, M.Y., Zhu, J.Y., Tao, A., Kautz, J., Catanzaro, B.: High-resolution
image synthesis and semantic manipulation with conditional gans. In: Proceedings
of the IEEE Conference on Computer Vision and Pattern Recognition (2018)
    </p>

    <br><br>

<hr>
<table align=center width=1100px>
  			  <tr>
  	              <td width=400px>
  					<left>
	  		  <center><h1>Contact</h1></center>
	  		  <center>Please Email Ningyuan ZHENG (<a href="mailto:ningyuaz@andrew.cmu.edu">ningyuaz@andrew.cmu.edu</a>) or Cheng-hsin Emily WUU (<a href="mailto:cwuu@andrew.cmu.edu">cwuu@andrew.cmu.edu</a>) for any questions.
</center>
			</left>
		</td>
			 </tr>
		</table>
              
</body>
</html>
 
